#!/usr/bin/env python3
# © 2014 jano <janoh@ksp.sk>
# © 2022 fezjo
# Complex script that can test solutions
description = """
Input tester.
Test all given solutions on all inputs.
By default, if outputs don't exits, use the first solution to generate them.
By default, automatically decide, how to compile and run solution.
"""
options = [
    "indir",
    "outdir",
    "progdir",
    "inext",
    "outext",
    "tempext",
    "reset",
    "timelimit",
    "warntimelimit",
    "memorylimit",
    "diffcmd",
    "showdiffoutput",
    "compile",
    "execute",
    "sort",
    "colorful",
    "colortest",
    "quiet",
    "stats",
    "nostats",
    "cleartemp",
    "clearbin",
    "programs",
    "fskip",
    "dupprog",
    "pythoncmd_test",
    "threads_test",
    "rustime",
]

import atexit
from concurrent.futures import ThreadPoolExecutor
import itertools
import os
from typing import Optional

from input_tool.common.commands import Config, get_statistics_header, Langs
from input_tool.common.messages import *
from input_tool.common.parser import Parser, ArgsTester
from input_tool.common.programs.checker import Checker
from input_tool.common.programs.program import Program
from input_tool.common.programs.solution import Solution
from input_tool.common.programs.validator import Validator

# ----------------- configuration ----------------


def parse_args() -> ArgsTester:
    parser = Parser(description, options)
    return parser.parse(ArgsTester)


def parse_timelimit(timelimit: str) -> Config.Timelimit:
    res: Config.Timelimit = {}
    for p in timelimit.split(","):
        ext, t = p.split("=") if "=" in p else ("", p)
        t = float(t)
        res[ext] = t
        res[Langs.from_ext(ext)] = t
    return res


def parse_warntimelimit(
    warntimelimit: str, timelimit: Config.Timelimit
) -> Config.Timelimit:
    if warntimelimit == "auto":
        return {k: v / 3 for k, v in timelimit.items()}
    return parse_timelimit(warntimelimit)


def setup_config(args: ArgsTester) -> None:
    Color.setup(args.colorful)

    if args.deprecated:
        for option in args.deprecated:
            warning(f"Option '{option}' is deprecated.")

    for key in (
        "progdir",
        "pythoncmd",
        "fskip",
        "memorylimit",
        "quiet",
        "compile",
        "execute",
    ):
        setattr(Config, key, getattr(args, key))
    Config.rus_time = os.access("/usr/bin/time", os.X_OK) and args.rustime
    if not Config.progdir:
        Config.progdir = None
    else:
        os.makedirs(Config.progdir, exist_ok=True)

    Config.timelimits.update(parse_timelimit(args.timelimit))
    Config.warn_timelimits.update(
        parse_warntimelimit(args.warntimelimit, Config.timelimits)
    )


# --------------- prepare programs ---------------


def get_relevant_prog_files_in_directory(directory: str) -> list[str]:
    return [
        os.path.normpath(de.path)
        for de in os.scandir(directory)
        if de.is_file()
        and any(cl.filename_befits(de.name) for cl in (Solution, Validator, Checker))
    ]


def get_relevant_prog_files_deeper(candidates: Sequence[str]) -> list[str]:
    return list(
        itertools.chain.from_iterable(
            get_relevant_prog_files_in_directory(p) if os.path.isdir(p) else [p]
            for p in candidates
        )
    )


def create_programs_from_files(
    files: Sequence[str], deduplicate: bool
) -> tuple[list[Solution | Validator], list[str]]:
    solutions: list[Solution | Validator] = []
    checker_files: list[str] = []
    if deduplicate:  # remove duplicate paths keeping order
        files = list(dict.fromkeys(files))
    for p in files:
        if Validator.filename_befits(p):
            solutions.append(Validator(p))
        elif Checker.filename_befits(p):
            checker_files.append(p)
        else:
            solutions.append(Solution(p))
    return solutions, checker_files


def create_checker(
    checker: Optional[str], checker_files: list[str], show_diff_output: bool
) -> Checker:
    if checker is not None:
        checker_files = [checker]
    if not checker_files:
        checker_files.append("diff")
    if len(checker_files) > 1:
        error(
            f"More than one checker found {checker_files}.\n"
            "Set explicitly with -d/--diffcmd (e.g. -d diff) "
            "or leave only one checker in the directory."
        )
    return Checker(checker_files[0], show_diff_output)


def cleanup(programs: Sequence[Program]) -> None:
    for p in programs:
        p.clear_files()
    if Config.progdir is not None:
        try:
            os.removedirs(Config.progdir)
        except OSError:
            warning(f"Program directory not empty {os.listdir(Config.progdir)}")


def prepare_programs(programs: Sequence[Program], threads: int) -> None:
    parallel_logger_manager = ParallelLoggerManager()
    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = [
            executor.submit(p.prepare, parallel_logger_manager.get_sink())
            for p in programs
        ]
        for future, logger in zip(futures, parallel_logger_manager.sinks):
            future.result()
            plain(logger.read())
        parallel_logger_manager.clear_buffers()


def deduplicate_solutions(
    solutions: Sequence[Solution | Validator],
) -> list[Solution | Validator]:
    d: dict[str, Program] = {}
    l: list[Solution | Validator] = []
    for s in solutions:
        key = s.run_cmd
        if key in d:
            warning(
                f"Solution {d[key].name} and {s.name} have the same run command. "
                "Keeping only first."
            )
        else:
            d[key] = s
            l.append(s)
    return l


def print_solutions_run_commands(solutions: list[Solution | Validator]) -> None:
    infob("----- Run commands -----")
    for s in solutions:
        infob(f"Program {s.name:{Config.cmd_maxlen}}   is ran as `{s.run_cmd}`")
    infob("------------------------")


# --------------- prepare io files ---------------


def get_inputs(args: ArgsTester) -> list[str]:
    return sorted(filter(lambda x: x.endswith(args.inext), os.listdir(args.indir)))


def get_outputs(args: ArgsTester) -> Optional[list[str]]:
    if args.outext != args.tempext and not args.reset:
        outputs = sorted(
            filter(lambda x: x.endswith(args.outext), os.listdir(args.outdir))
        )
        if len(outputs) > 0 and len(outputs) < len(inputs):
            warning("Incomplete output files.")
        return outputs
    else:
        infob("Outputs will be regenerated")
        return None


def temp_clear(args: ArgsTester) -> None:
    tempfiles = sorted(
        filter(lambda x: x.endswith(args.tempext), os.listdir(args.outdir))
    )
    if len(tempfiles):
        info(f"Deleting all .{args.tempext} files")
        for tempfile in tempfiles:
            os.remove(args.outdir + "/" + tempfile)


# ---------------- test solutions ----------------


def get_result_file(
    out_file: str, temp_file: str, isvalidator: bool, force: str = "none"
):
    if isvalidator or force == "temp":
        return temp_file
    if not os.path.exists(out_file) or force == "out":
        return out_file
    return temp_file


def get_output_creation_message(output_file: str) -> str:
    reason = ("doesn't exist", "recompute")[os.path.exists(output_file)]
    return f"File {output_file} will be created now ({reason})."


def general_run_sol(
    sol: Solution, ifile: str, ofile: str, rfile: str, cleartemp: bool, *rargs: Any
) -> None:
    try:
        sol.run(ifile, ofile, rfile, checker, *rargs)
        if cleartemp and ofile != rfile and os.path.exists(rfile):
            os.remove(rfile)
    except Exception as err:
        error(err)


def test_all(
    solutions: Sequence[Solution | Validator],
    inputs: Sequence[str],
    threads: int,
    args: ArgsTester,
) -> None:
    """
    First solution generates output file if it doesn't exist. All the other
    solutions can run in parallel however, they can't be checked via the Checker
    unless the output file is generated. They wait for Event, which is triggered
    when the generating solution thread finishes.

    The logs from all the threads are stored separately. Whenever a thread
    finishes, the corresponding logger closes and triggers an Event.
    Subsequently, the main thread reads as many of the closed logs as possible
    and prints them.
    """
    parallel_logger_manager = ParallelLoggerManager()

    def logger_close_and_trigger(logger: BufferedLogger) -> None:
        logger.close()
        parallel_logger_manager.closed_event.set()

    with ThreadPoolExecutor(max_workers=threads) as executor:
        for input in inputs:
            input_file = args.indir + "/" + input
            prefix = args.outdir + "/" + input.rsplit(".", 1)[0]
            output_file = prefix + "." + args.outext
            temp_file = prefix + ".s{:0>2}." + args.tempext

            testcase_logger = parallel_logger_manager.get_sink()
            if len(solutions) > 1:
                testcase_logger.info(f"{input} >")

            def run_sol(
                sol: Solution,
                rfile: str,
                *rargs: Any,
                ifile: str = input_file,
                ofile: str = output_file,
            ) -> None:
                general_run_sol(sol, ifile, ofile, rfile, args.cleartemp, *rargs)

            output_ready = checker.output_ready[input_file]
            output_ready.clear()
            generated_output = False
            for si, sol in enumerate(solutions):
                result_force = (
                    "temp" if generated_output else "out" if args.reset else "none"
                )
                result_file = get_result_file(
                    output_file,
                    temp_file.format(si),
                    isinstance(sol, Validator),
                    result_force,
                )

                is_generator = result_file == output_file
                logger = parallel_logger_manager.get_sink()
                future = executor.submit(
                    run_sol, sol, result_file, is_generator, logger
                )
                if is_generator:
                    testcase_logger.infob(get_output_creation_message(output_file))
                    generated_output = True
                    future.add_done_callback(lambda _, o=output_ready: o.set())
                future.add_done_callback(
                    lambda _, l=logger: logger_close_and_trigger(l)
                )

            if not generated_output:
                output_ready.set()
            logger_close_and_trigger(testcase_logger)

        while parallel_logger_manager.last_open < len(parallel_logger_manager.sinks):
            parallel_logger_manager.closed_event.wait()
            parallel_logger_manager.closed_event.clear()
            plain(parallel_logger_manager.read_closed())


def print_summary(solutions: Sequence[Solution | Validator], inputs: Sequence[str]):
    print(get_statistics_header(inputs))
    for s in solutions:
        print(s.get_statistics())


# --------------------- FLOW ---------------------

args = parse_args()
if args.colortest:
    color_test()
    quit()
setup_config(args)

files = get_relevant_prog_files_deeper(args.programs)
solutions, checker_files = create_programs_from_files(files, not args.dupprog)
checker = create_checker(args.diffcmd, checker_files, args.showdiffoutput)
if args.sort:
    solutions.sort()
programs = [checker] + solutions

if args.clearbin:
    atexit.register(lambda p=programs: cleanup(p))

prepare_programs(programs, max(4, args.threads))
if not args.dupprog:  # multiple solutions can have same run command after compilation
    solutions = deduplicate_solutions(solutions)

for s in solutions:
    Config.cmd_maxlen = max(Config.cmd_maxlen, len(s.name))
Config.inside_oneline = len(solutions) <= 1
print_solutions_run_commands(solutions)

inputs = get_inputs(args)
outputs = get_outputs(args)
temp_clear(args)
Config.inside_inputmaxlen = max(map(len, inputs))

test_all(solutions, inputs, args.threads, args)
if args.stats:
    print_summary(solutions, inputs)
