#!/usr/bin/env python3
# (c) 2014 jano <janoh@ksp.sk>
# Complex script that can test solutions
description = """
Input tester.
Test all given solutions on all inputs.
By default, if outputs don't exits, use the first solution to generate them.
By default, automatically decide, how to compile and run solution.
"""
options = [
    "indir",
    "outdir",
    "progdir",
    "inext",
    "outext",
    "tempext",
    "reset",
    "timelimit",
    "warntimelimit",
    "memorylimit",
    "diffcmd",
    "compile",
    "execute",
    "sort",
    "colorful",
    "colortest",
    "quiet",
    "stats",
    "nostats",
    "cleartemp",
    "clearbin",
    "programs",
    "fskip",
    "dupprog",
    "pythoncmd_test",
    "threads_test",
    "rustime",
]

import atexit
from concurrent.futures import ThreadPoolExecutor
import itertools
import os

from input_tool.common.commands import (
    Langs,
    Config,
    Program,
    Solution,
    Validator,
    Checker,
)
from input_tool.common.messages import *
from input_tool.common.parser import Parser, ArgsTester

parser = Parser(description, options)
args = parser.parse(ArgsTester)
if args.colortest:
    color_test()
    quit(0)

Color.setup(args.colorful)

if args.deprecated:
    for option in args.deprecated:
        warning(f"Option '{option}' is deprecated.")

for key in (
    "progdir",
    "pythoncmd",
    "fskip",
    "memorylimit",
    "quiet",
    "compile",
    "execute",
):
    setattr(Config, key, getattr(args, key))
Config.rus_time = os.access("/usr/bin/time", os.X_OK) and args.rustime
os.makedirs(Config.progdir, exist_ok=True)


def parse_timelimit(str_timelimit: str) -> dict[Langs.Lang | str, float]:
    res: dict[Langs.Lang | str, float] = {}
    for p in str_timelimit.split(","):
        ext, t = p.split("=") if "=" in p else ("", p)
        t = float(t)
        res[ext] = t
        res[Langs.from_ext(ext)] = t
    return res


Config.timelimits.update(parse_timelimit(args.timelimit))
Config.warn_timelimits.update(parse_timelimit(args.warntimelimit))

# {{{ ------------ prepare programs ------------------


def get_relevant_prog_files_in_directory(directory: str) -> list[str]:
    return [
        de.path
        for de in os.scandir(directory)
        if de.is_file()
        and any(cl.filename_befits(de.name) for cl in (Solution, Validator, Checker))
    ]


solutions: list[Solution | Validator] = []
checkers: list[str] = []
files = list(
    itertools.chain.from_iterable(
        get_relevant_prog_files_in_directory(p) if os.path.isdir(p) else [p]
        for p in args.programs
    )
)
if not args.dupprog:  # remove duplicate paths keeping order
    files = list(dict.fromkeys(files))
for p in files:
    if Validator.filename_befits(p):
        solutions.append(Validator(p))
    elif Checker.filename_befits(p):
        checkers.append(p)
    else:
        solutions.append(Solution(p))
if args.diffcmd is not None:
    checkers = [args.diffcmd]
if not checkers:
    checkers.append("diff")
if len(checkers) > 1:
    error(
        f"More than one checker found {checkers}.\n"
        + "Set explicitly with -d/--diffcmd (e.g. -d diff) "
        + "or leave only one checker in the directory."
    )
checker: Checker = Checker(checkers[0])
if args.sort:
    solutions.sort()
programs = [checker]
programs += solutions


def cleanup() -> None:
    if args.clearbin:
        for p in programs:
            p.clear_files()
        try:
            os.rmdir(Config.progdir)
        except OSError:
            warning(f"Program directory not empty {os.listdir(Config.progdir)}")


atexit.register(cleanup)

parallel_logger_manager = ParallelLoggerManager()
with ThreadPoolExecutor(max_workers=max(4, args.threads)) as executor:
    futures = [
        executor.submit(p.prepare, parallel_logger_manager.get_sink()) for p in programs
    ]
    for future, logger in zip(futures, parallel_logger_manager.sinks):
        future.result()
        plain(logger.read())
    parallel_logger_manager.clear_buffers()

# multiple solutions can have same run command after compilation
if not args.dupprog:
    d: dict[str, Program] = {}
    l: list[Solution | Validator] = []
    for s in solutions:
        key = s.run_cmd
        if key in d:
            warning(
                f"Solution {d[key].name} and {s.name} have the same run command. "
                "Keeping only first."
            )
        else:
            d[key] = s
            l.append(s)
    solutions = l

# }}}
# {{{ ------------ prepare inputs ----------------

inputs = sorted(filter(lambda x: x.endswith(args.inext), os.listdir(args.indir)))

if args.outext != args.tempext and not args.reset:
    outputs = sorted(filter(lambda x: x.endswith(args.outext), os.listdir(args.outdir)))
    if len(outputs) > 0 and len(outputs) < len(inputs):
        warning("Incomplete output files.")
else:
    infob("Outputs will be regenerated")


def get_result_file(
    out_file: str, temp_file: str, isvalidator: bool, force: str = "none"
):
    if isvalidator or force == "temp":
        return temp_file
    if not os.path.exists(out_file) or force == "out":
        return out_file
    return temp_file


def temp_clear() -> None:
    tempfiles = sorted(
        filter(lambda x: x.endswith(args.tempext), os.listdir(args.outdir))
    )
    if len(tempfiles):
        info(f"Deleting all .{args.tempext} files")
        for tempfile in tempfiles:
            os.remove(args.outdir + "/" + tempfile)


temp_clear()

Config.inside_oneline = len(solutions) <= 1
Config.inside_inputmaxlen = max(map(len, inputs))

# }}}

# ------------ test solutions ----------------


def get_output_creation_message(output_file: str) -> str:
    reason = ("doesn't exist", "recompute")[os.path.exists(output_file)]
    return f"File {output_file} will be created now ({reason})."


def general_run_sol(
    sol: Solution, input_file: str, output_file: str, result_file: str, *rargs: Any
) -> None:
    try:
        sol.run(input_file, output_file, result_file, checker, *rargs)
        if (
            args.cleartemp
            and output_file != result_file
            and os.path.exists(result_file)
        ):
            os.remove(result_file)
    except Exception as err:
        error(err)


parallel_logger_manager = ParallelLoggerManager()


def logger_close_and_trigger(logger: BufferedLogger) -> None:
    logger.close()
    parallel_logger_manager.closed_event.set()


with ThreadPoolExecutor(max_workers=args.threads) as executor:
    for input in inputs:
        input_file = args.indir + "/" + input
        prefix = args.outdir + "/" + input.rsplit(".", 1)[0]
        output_file = prefix + "." + args.outext
        temp_file = prefix + ".s{:0>2}." + args.tempext

        testcase_logger = parallel_logger_manager.get_sink()
        if len(solutions) > 1:
            testcase_logger.info(f"{input} >")

        run_sol = lambda sol, resf, *rargs, inpf=input_file, outf=output_file: (
            general_run_sol(sol, inpf, outf, resf, *rargs)
        )

        output_ready = checker.output_ready[input_file]
        output_ready.clear()
        generated_output = False
        for si, sol in enumerate(solutions):
            result_force = (
                "temp" if generated_output else "out" if args.reset else "none"
            )
            result_file = get_result_file(
                output_file,
                temp_file.format(si),
                isinstance(sol, Validator),
                result_force,
            )

            is_generator = result_file == output_file
            logger = parallel_logger_manager.get_sink()
            future = executor.submit(run_sol, sol, result_file, is_generator, logger)
            if is_generator:
                testcase_logger.infob(get_output_creation_message(output_file))
                generated_output = True
                future.add_done_callback(lambda _, o=output_ready: o.set())
            future.add_done_callback(lambda _, l=logger: logger_close_and_trigger(l))

        if not generated_output:
            output_ready.set()
        logger_close_and_trigger(testcase_logger)

    while parallel_logger_manager.last_open < len(parallel_logger_manager.sinks):
        parallel_logger_manager.closed_event.wait()
        parallel_logger_manager.closed_event.clear()
        plain(parallel_logger_manager.read_closed())


# ------------ print sumary ------------------

if args.stats:
    print(Solution.get_statistics_header(inputs))
    for s in solutions:
        print(s.get_statistics())
